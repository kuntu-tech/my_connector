from datetime import datetime
import json
import sys
import os
import asyncio
import time
from agents import Agent, Runner, function_tool, ModelSettings, HostedMCPTool,SQLiteSession,WebSearchTool
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
sys.path.append(str(Path(__file__).resolve().parent.parent))
from question_check_test import checkquestion_with_gpt


### ä¼ å‚
# 1. SUPABASE_PROJECT_URL 
# 2. SUPABASE_ACCESS_TOKEN 
# 3. USER_NAME
# 4. æ•°æ®å®¡æŸ¥çš„ç»“æžœï¼šåªæœ‰ä¸ºtrueæ‰æ‰§è¡Œ

### è¾“å‡º
# 1. æ­¤ä»£ç ä¸­outåˆ°æ–‡ä»¶ä¸­çš„å†…å®¹ï¼Œåº”è¯¥å…¥åº“åˆ°â€aiåˆ†æžâ€œä¸­çš„â€resultsâ€œ
# 2. å…¥åº“åŽï¼Œåº”è¯¥å‘é€æç¤ºç»™éœ€è¦æ­¤æ•°æ®çš„æ¨¡å—

load_dotenv()
SUPABASE_PROJECT_ID = os.getenv("SUPABASE_PROJECT_ID")
SUPABASE_ACCESS_TOKEN = os.getenv("SUPABASE_ACCESS_TOKEN")  # Personal Access Token (PAT)
SUPABASE_MCP_URL = f"https://mcp.supabase.com/mcp?project_ref={SUPABASE_PROJECT_ID}"
USER_NAME = "huimin"
OPENAI_API_KEY=os.getenv("OPENAI_API_KEY")


### 1. è¯»å–æç¤ºè¯
BUSINESS_EXPERT_PROMPT=(Path(__file__).resolve().parent / "demo2" / "system_prompt.md").read_text(encoding="utf-8")
MARKET_ANALYSIS_PROMPT=(Path(__file__).resolve().parent / "demo2" / "market_analysis_prompt.md").read_text(encoding="utf-8")
AUDIENCE_ANALYSIS_PROMPT=(Path(__file__).resolve().parent / "demo2" / "audience_analysis_prompt.md").read_text(encoding="utf-8")


### 2. å·¥å…·å‡½æ•°
def audit_table_with_gpt(table_info):
    # print(table_name,schema_data,sample_data)
    client = OpenAI(api_key=OPENAI_API_KEY)
    # print(client)
    prompt = f"""
ä½ æ˜¯ä¸€åæ•°æ®åˆè§„æ€§å®¡æŸ¥ä¸“å®¶ã€‚è¯·æ ¹æ® OpenAI æ•°æ®æ”¿ç­–ï¼Œå¯¹ä»¥ä¸‹ Supabase çš„è¡¨è¿›è¡Œåˆ†æžï¼š
ä»¥ä¸‹è¡¨ä¿¡æ¯ï¼š{table_info}è¿›è¡Œæ•°æ®å®¡æŸ¥
è¦æ±‚ï¼š
1. æŒ‡å‡ºå¯èƒ½çš„ä¸ªäººè”ç³»æ–¹å¼æˆ–å®—æ•™ã€æ”¿æ²»ã€æœªæˆå¹´äººç­‰æ•æ„Ÿä¿¡æ¯å­—æ®µï¼›
2. è¯´æ˜Žæ˜¯å¦è¿åæ•°æ®åˆè§„è§„èŒƒï¼›
3.æŒ‰ç…§JSONæ ¼å¼è¿›è¡Œè¾“å‡º
4.è¾“å‡ºå­—æ®µåªåŒ…å«table_name,contains_personal_data,contains_sensitive_data,contains_sensitive_fields,allowed_to_use
5.å¦‚æžœcontains_sensitive_data is Trueï¼Œåˆ™å°†å…·ä½“çš„å­—æ®µè¾“å‡ºåˆ°contains_sensitive_fieldsä¸­ï¼Œå¦‚æžœcontains_sensitive_data is Falseï¼Œcontains_sensitive_fieldsä¸ºNone
6.è¾“å‡ºè¯­è¨€ä¸ºè‹±è¯­
"""

    print(f"æ­£åœ¨è¿›è¡Œè¡¨ï¼š{table_info.get('table_name')}çš„æ•°æ®å®¡æŸ¥ ...")
    # print(table_info)
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        # temperature=0
    )
    # print(response)
    report = response.choices[0].message.content
    # print(f"\nðŸ“‹ å®¡æŸ¥ç»“æžœï¼š\n", report)
    return report
#æ•°æ®å®¡æŸ¥ä¸»æµç¨‹
def data_check(tables_info):
    reports_list = []
    all_allowed = True  # ç”¨äºŽåˆ¤æ–­æ•´ä½“ç»“è®º
    for table in tables_info:
        try:
            report = audit_table_with_gpt(table)
            report_json = json.loads(report)
            reports_list.append(report_json)
            # åˆ¤æ–­æ˜¯å¦å…è®¸ä½¿ç”¨
            if not report_json.get("allowed_to_use", False):
                all_allowed = False
        except Exception as e:
            print(f"å®¡æŸ¥ {table} å¤±è´¥ï¼š{e}")
            report_json = {"table_name": table.get("table_name", "unknown"), "allowed_to_use": False, "error": str(e)}
            reports_list.append(report_json)
            all_allowed = False
    
    # ç»Ÿä¸€æ€»ç»“æŠ¥å‘Š
    summary = {
        "tables_audited": reports_list,
        "final_conclusion": all_allowed
    }
    print("æ€»ç»“æŠ¥å‘Šï¼š")
    print(json.dumps(summary, indent=4, ensure_ascii=False))
    # è¿”å›ž True / False ä¿¡å·
    return all_allowed, summary

@function_tool
def get_current_time()-> str:
    return datetime.now().astimezone().isoformat()



### 3. ä¸»å‡½æ•°
async def main():
    agent = Agent(
        name='business_expert',
        instructions = BUSINESS_EXPERT_PROMPT,
        model = 'gpt-4.1-mini',
        model_settings=ModelSettings(
            temperature=0.7,
            top_p=0.9
        ),
        tools = [
            HostedMCPTool(
                tool_config={
                    'type':"mcp",
                    "server_label":"supabase",
                    "server_url":SUPABASE_MCP_URL,
                    "authorization":SUPABASE_ACCESS_TOKEN,
                    "require_approval":"never"
                }
            ),
            get_current_time,
            WebSearchTool(),
            # CodeInterpreterTool(),
        ],
        
    )
    session = SQLiteSession(USER_NAME,f"{USER_NAME}_conversations.db")    	
    print(" =======  schema_description  ======= ")
    schema_analysis = await Runner.run(
        agent,
        input="""use supabase mcp tools, give me a description in Supabase public schema.
        """,
        session=session
    )
    schema_analysis_output = schema_analysis.final_output
    print(f"Schema analysis output: {schema_analysis_output}")
    try:
        schema_analysis_json = json.loads(schema_analysis_output)
    except json.JSONDecodeError as e:
        print(f"JSON decode error: {e}")
        print("Creating mock schema data for testing...")
        schema_analysis_json = {
            "description": {
                "tables": [
                    {
                        "table_name": "test_table",
                        "columns": ["id", "name", "created_at"],
                        "sample_data": [{"id": 1, "name": "test", "created_at": "2024-01-01"}]
                    }
                ]
            }
        }
    output_dir = Path(__file__).resolve().parent / "outputs-1"
    output_dir.mkdir(exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    md_path = output_dir / f"schema_description _{timestamp}.md"
    md_path.write_text(schema_analysis_output, encoding="utf-8")
    print(" =======  data_check  ======= ")  
    tables_info = schema_analysis_json.get("description")["tables"]
    all_allowed,summary = data_check(tables_info)
    # ----------------------
    # -------------------------
    if all_allowed:
        print("======== Market Analysis ========")
        market_analysis = await Runner.run(
            agent,
            input=MARKET_ANALYSIS_PROMPT,
            session=session
        )
        output = market_analysis.final_output
        output_dir = Path(__file__).resolve().parent / "outputs-1"
        output_dir.mkdir(exist_ok=True)
        md_path = output_dir / f"market_analysis_{timestamp}.md"
        md_path.write_text(output, encoding="utf-8")
        print("market analysis finished.")
        print("======== audience Analysis =========")
        audience_analysis = await Runner.run(
            agent, 
            input = AUDIENCE_ANALYSIS_PROMPT,
            session=session
            )
        audience_analysis_output = audience_analysis.final_output
        output_dir = Path(__file__).resolve().parent / "outputs-1"
        output_dir.mkdir(exist_ok=True)
        md_path = output_dir / f"audience_analysis_{timestamp}.md"
        md_path.write_text(audience_analysis_output, encoding="utf-8")
        print("audience analysis finished.")

        ## é—®é¢˜å®¡æŸ¥
        print("=======  data modeling validation ========")
        results_json = json.loads(audience_analysis_output)
        reports_list = []
        for segment in results_json.get("segments", []):
            segment_name = segment.get("segment_name", "unknown_segment")
            for question in segment.get("valued_questions", []):
                print(f"---- {segment_name}")
                report = checkquestion_with_gpt(question, schema_analysis_output)
                reports_list.append(report)
        print(reports_list)
    else:
        output_info = summary
        print(output_info)
	
if __name__ == "__main__":
    asyncio.run(main())