#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¦»çº¿æµ‹è¯•å“ç‰Œç­–ç•¥Agentè„šæœ¬
ä¸ä¾èµ–ç½‘ç»œè°ƒç”¨ï¼Œåªæµ‹è¯•åŸºæœ¬åŠŸèƒ½
"""

import json
import os
import sys
from datetime import datetime
from pathlib import Path

def test_offline_functionality():
    """æµ‹è¯•ç¦»çº¿åŠŸèƒ½"""
    print("=== å“ç‰Œç­–ç•¥Agentç¦»çº¿æµ‹è¯• ===")
    
    # 1. æµ‹è¯•é…ç½®æ–‡ä»¶è¯»å–
    config_file = Path(__file__).resolve().parent / "config.json"
    if config_file.exists():
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        print(f"[OK] é…ç½®æ–‡ä»¶è¯»å–æˆåŠŸ: {list(config.keys())}")
    else:
        print("[ERROR] é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    # 2. æµ‹è¯•ç¯å¢ƒå˜é‡è®¾ç½®
    if 'openai_api_key' in config:
        os.environ['OPENAI_API_KEY'] = config['openai_api_key']
        print("[OK] OpenAI APIå¯†é’¥è®¾ç½®æˆåŠŸ")
    
    if 'supabase_project_id' in config:
        os.environ['SUPABASE_PROJECT_ID'] = config['supabase_project_id']
        print("âœ“ Supabaseé¡¹ç›®IDè®¾ç½®æˆåŠŸ")
    
    # 3. æµ‹è¯•æ—¶é—´æˆ³ç”Ÿæˆ
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    print(f"âœ“ æ—¶é—´æˆ³ç”Ÿæˆ: {timestamp}")
    
    # 4. æµ‹è¯•ç›®å½•æ“ä½œ
    outputs_dir = Path(__file__).resolve().parent / "outputs"
    outputs_dir.mkdir(exist_ok=True)
    print(f"âœ“ è¾“å‡ºç›®å½•åˆ›å»º: {outputs_dir}")
    
    # 5. æµ‹è¯•æ–‡ä»¶æŸ¥æ‰¾
    existing_files = list(outputs_dir.glob("integrated_analysis_*.json"))
    print(f"âœ“ æ‰¾åˆ°ç°æœ‰æ–‡ä»¶æ•°é‡: {len(existing_files)}")
    
    if existing_files:
        latest_file = max(existing_files, key=lambda x: x.stat().st_mtime)
        print(f"âœ“ æœ€æ–°æ–‡ä»¶: {latest_file.name}")
        
        # è¯»å–å¹¶æ˜¾ç¤ºæ–‡ä»¶å†…å®¹
        data = json.loads(latest_file.read_text(encoding="utf-8"))
        print(f"âœ“ æ–‡ä»¶å†…å®¹: {data}")
    else:
        # åˆ›å»ºæ–°çš„æµ‹è¯•æ–‡ä»¶
        test_file = outputs_dir / f"integrated_analysis_{timestamp}.json"
        sample_data = {
            "timestamp": timestamp,
            "analysis_type": "integrated_analysis",
            "status": "test",
            "data": {
                "brand_name": "æµ‹è¯•å“ç‰Œ",
                "description": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å“ç‰Œæè¿°",
                "market_analysis": {
                    "target_market": "ç§‘æŠ€è¡Œä¸š",
                    "competitors": ["å“ç‰ŒA", "å“ç‰ŒB"],
                    "opportunities": ["æ–°å…´å¸‚åœº", "æŠ€æœ¯åˆ›æ–°"]
                },
                "audience_analysis": {
                    "primary_audience": "å¹´è½»ä¸“ä¸šäººå£«",
                    "demographics": {
                        "age": "25-35",
                        "income": "ä¸­é«˜æ”¶å…¥",
                        "interests": ["ç§‘æŠ€", "åˆ›æ–°", "æ•ˆç‡"]
                    }
                }
            }
        }
        test_file.write_text(json.dumps(sample_data, ensure_ascii=False, indent=2), encoding="utf-8")
        print(f"âœ“ åˆ›å»ºæµ‹è¯•æ–‡ä»¶: {test_file.name}")
        data = sample_data
    
    # 6. æ¨¡æ‹Ÿå“ç‰Œç­–ç•¥å¤„ç†ï¼ˆä¸è°ƒç”¨AIï¼‰
    print("\n=== æ¨¡æ‹Ÿå“ç‰Œç­–ç•¥å¤„ç† ===")
    
    # åŸºäºç°æœ‰æ•°æ®ç”Ÿæˆå“ç‰Œç­–ç•¥
    brand_strategy = {
        "chatapp_name": "Aurora Insights",
        "chatapp_description": "An AI-powered brand platform that transforms analytical insights into compelling, market-ready product narratives.",
        "chatapp_core_features": [
            {
                "feature_title": "Brand Positioning Engine",
                "intro": "Defines the brand's competitive edge and value promise using structured strategic logic."
            },
            {
                "feature_title": "Market Intelligence Hub", 
                "intro": "Aggregates and analyzes market data to identify opportunities and trends."
            },
            {
                "feature_title": "Audience Insight Generator",
                "intro": "Creates detailed audience personas and behavioral analysis."
            },
            {
                "feature_title": "Narrative Builder",
                "intro": "Transforms insights into compelling brand stories and messaging."
            }
        ]
    }
    
    # 7. ä¿å­˜å“ç‰Œç­–ç•¥ç»“æœ
    strategy_file = outputs_dir / f"brand_strategy_{timestamp}.json"
    strategy_file.write_text(json.dumps(brand_strategy, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"âœ“ å“ç‰Œç­–ç•¥ç»“æœä¿å­˜: {strategy_file.name}")
    
    # 8. æ˜¾ç¤ºç»“æœ
    print("\n=== å“ç‰Œç­–ç•¥ç»“æœ ===")
    print(f"åº”ç”¨åç§°: {brand_strategy['chatapp_name']}")
    print(f"åº”ç”¨æè¿°: {brand_strategy['chatapp_description']}")
    print("\næ ¸å¿ƒåŠŸèƒ½:")
    for i, feature in enumerate(brand_strategy['chatapp_core_features'], 1):
        print(f"  {i}. {feature['feature_title']}")
        print(f"     {feature['intro']}")
    
    print("\n=== æµ‹è¯•å®Œæˆ ===")
    print("âœ… æ‰€æœ‰ç¦»çº¿åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
    print(f"ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  - {latest_file.name if existing_files else test_file.name}")
    print(f"  - {strategy_file.name}")
    
    return True

if __name__ == "__main__":
    try:
        success = test_offline_functionality()
        if success:
            print("\nğŸ‰ è„šæœ¬åŸºæœ¬åŠŸèƒ½æ­£å¸¸ï¼Œå¯ä»¥æ­£å¸¸è¿è¡Œï¼")
        else:
            print("\nâŒ è„šæœ¬å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦ä¿®å¤")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
